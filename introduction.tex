\section {Introduction (and Inspiration/Motivation)}

The area of author attribution is a thriving field that can benefit from better alignment techniques. Sometimes, a researcher aims to detect imitations in an effort to determine whether work has been plagiarized. Sometimes the task is to simply assist in the effort of citing work\footnote{This is the case for us for http://scriptures.byu.edu/}. In this work, we divide intertexts into classes, or types: exact quote, non-exact quote, fragment, lazy quote, paraphrase, and allusion (see Table \ref{tab:imitation-types}). Collectively, we refer to these as \textit{imitations}. We compare various genetic alignment algorithms and their performance. Then we use their output and their metadata of the resultant genes to train several machine learning models. 

In this work, we do not detect imitations; we only aim to align them. 

Our primary, or imitable documents, include \textit{The Holy Bible KJV}, \textit{The Holy Bible JST} (Joseph Smith Translation), \textit{The Book of Mormon}, \textit{The Doctrine \& Covenants}, and \textit{The Pearl of Great Price} as sources. Secondary documents---those that attempt to imitate the primary documents---are composed of religious discourse texts: 10 volumes of the Journals of Discourse. ``The Journal of Discourses is not an official publication of The Church of Jesus Christ of Latter-day Saints. It is a compilation of sermons and other materials from the early years of the Church, which were transcribed and then published. It included some doctrinal instruction but also practical teaching, some of which is speculative in nature and some of which is only of historical interest.'' (http://www.lds.org/topics/journal-of-discourses) The discourses were last published in 1886. Using a database of pre-aligned imitations as a gold standard, we compute the error of various machine learning models in terms of error rate. For error measures: We focus on only the right position of the alignments since we aim to insert imitations where it seems most appropriate for them.

After determining which version of genetic algorithm works best , we use the output and meta-data of the alignments (length, number of matches, number of indels, and number of replaces, etc.) and target (gold standard alignment position) as input to the machine learning models. %We found that there were xyz clusters, each corresponding to exact quote, non-exact, paraphrase, or allusion. This empirically demonstrates that given just xyz algorithms, we can discern between types of attribution that is called for. It is not outside the realm of possibilities for future work to use this technique to classify work at run-time before making a conclusion as to the badness of the imitation attempt.
According to overall error rates, the multi-layer perceptron, a non-linear neural network outperforms all genetic alignment algorithms. Another run of models shows that a bagging method further decreases error. %This was also true with respect to each imitation type.

This study aims to prove the following hypotheses:
	\begin{quote}
		$H_{1}:$ The error of any of our genetic algorithms is better than the random mean absolute error of $160$.

		$H_{2}:$ Given genetic alignment meta-data from multiple runs, machine learning models can be trained to reduce error rates on imitation alignments.
		
		%$H_{3}:$ Given the meta-data of the text, we can classify the type of imitation with xyz\% accuracy.	
	\end{quote}

%Herein we also show the classification confusion matrix for type of imitation, which is not revelatory, but informative nonetheless.  [Future work: also show the meta-data profile, including a word-length histogram, word-token-length histogram, etc.].  
