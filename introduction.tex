\section {Introduction (and Inspiration/Motivation)}

The work of author attribution is applicable and researchable in both secular and non-secular fields. This is true regardless of whether the imitation is an exact quote, non-exact quote, paraphrase, or allusion. Collectively, we refer to these as \textit{imitations}. First we compare various genetic alignment algorithms and their performance. Then we use their output as well as other metadata of the citations to train multiple neural networks using regressive back-propogation. 

In this work, we do not detect imitations; we only aim to align them. 

Our primary, or imitable documents, include \textit{The Holy Bible KJV}, \textit{The Holy Bible JST} (Joseph Smith Translation), \textit{The Book of Mormon}, \textit{The Doctrine \& Covenants}, and \textit{The Pearl of Great Price} as sources. Secondary documents---those that attempt to imitate the primary documents---are composed of religious discourse texts: 10 volumes of the Journals of Discourse. These are LDS\footnote{Acronym for ``The Church of Jesus Christ of Latter-day Saints''. The LDS are sometimes referred to as ``Mormons'' although some offshoot churches call themselves ``Mormons'' while having drastically different beliefs. Thus we opt to use \textit{LDS} here to name them} discourses from the 19th (20th?) century. Using a database of pre-aligned citation alignments, citation class, and scripture citation passages, we compare various genetic algorithms in terms of error rate. %and perhaps other metrics 
[For error measures: We focus on only the right position of the alignments since we aim to insert citations where it seems most appropriate for them.] We then determine which of all the genetic algorithms have the least error for each type of citation.

After determining which version of genetic algorithm works best for each type of citation, we use the meta-data of the alignments (length, number of matches, number of indels, and number of replaces, etc.) and target (gold standard alignment positions) as input to the training of a neural network. %We found that there were xyz clusters, each corresponding to exact quote, non-exact, paraphrase, or allusion. This empirically demonstrates that given just xyz algorithms, we can discern between types of attribution that is called for. It is not outside the realm of possibilities for future work to use this technique to classify work at run-time before making a conclusion as to the badness of the imitation attempt.
According to overall error rates, all high-order and low-order neural networks outperformed all genetic alignment algorithms. This was also true for each imitation type.

This study aims to prove the following hypothesis:
	\begin{quote}
		$H_{1}:$ The error of any of our genetic algorithms is better than the baseline error of 232.

		$H_{2}:$ Given output and meta-data of genetic alignments, a neural network can be trained to produce lower error rates on citation alignments than any of them alone.

		%$H_{3}:$ Given the meta-data of the text, we can classify the type of imitation with xyz\% accuracy.		
	\end{quote}

%Herein we also show the classification confusion matrix for type of imitation, which is not revelatory, but informative nonetheless.  [Future work: also show the meta-data profile, including a word-length histogram, word-token-length histogram, etc.].  
