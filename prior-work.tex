\section {Prior/Related Work on Imitation Alignment}
Related work in the realm of imitation alignment include work in the following topics:
	\begin{itemize}
		\item Plagiarism detection (and software)
		\item Author attribution
		\item Author identification
	\end{itemize}

We found no instances of work that aimed to use regresssion via machine learning as a second step to refine alignments obtained from a genetic alignment algorithm.%classify/categorize/cluster imitations. We also found no instances of work that used machine learning to train a regressive ANN with better error rates than the algorithms used to produce the training data.


\subsection{Author Attribution}

\subsection{Imitation Detection}
One might define \textit{plagiarism} as attempting (or succeeding) at passing off another's work as one's own. This includes, but is not limited to, text. Plagiarism detection has been applied with some success in the area detecting whether computer program code was copied. Indeed, some universities have implemented code-plagiarism detectors (citation xyz).

Here we do not detect imitations, but rather align text marked as containing instances of imitation \footnote{Furthermore, we make no attempt to chastise the authors of the imitations since in order to know whether they were truly plagiarizing, we would have to verify that they did not cite the source (a supervised task). We leave the human intervention to future work. (And since our text is from the 19th century, we could not chastise the speaker even if we wanted to do so.)}.

\subsubsection{Alignment (Genetic and non-Genetic)}
Methods besides genetic alignment have been used before to align text. They are most often found as a sub-algorithm rather than a means to an end. Furthermore, it is often used for something other than imitation alignment. For example, Bill Lund in \cite{lund_binarization} uses a modified A* search to align varied levels of binarized forms of the same text to better perform OCR.

Showing that genetic alignment is a viable approach is one of our hopes.

\subsubsection{Fuzzy Metric}
Other methods of detecting possible paraphrase include fuzzy searches. Hilton III, \cite{hilton_2012}, used one algorithm to do this. He was successful at finding instances of un-cited imitation between prophets within \textit{The Book of Mormon}.

The downside to the algorithm he used is that it was a highly supervised algorithm. It required a lot of parameters to be tested, tweaked, and set. Furthermore, the output often required that Hilton filter the results himself. This is a supervised method at best. Nevertheless, the algorithm did rank results, making it easy for Hilton to simply stop investigating input upon reaching any false positives.

\subsubsection{Intrinsic Author ID}
Interesting work that could be combined with our methods here including intrinsic author identification. This is the process of identifying which subtexts are least likely to be author by the speaker/writer. One can imigine using this as meta-data input to the BP-MLP that we will describe later.

\subsubsection{Error Rates of Alignments}
Since much work aims to pair documents as related, sometimes the error rates must take into account up to 4 positions at a time: the left and right end of imitated/imitating text in both documents (2 ends * 2 documents = 4). %The metric for measuring accuracy of any algorithm that aims to do this can be hairy (wc: use other word). One method includes using the BLEU? method.
Aligning both sides well is important, especially when neither is known to be the original work by predating the other. However, when 1 piece of meta-data is known, namely the timestamp of creation, for both documents, suddenly knowing which is the imitation is trivial. Nevertheless, the interest in the alignments for both sides remains of interest, at least for comparing methods of alignment.
