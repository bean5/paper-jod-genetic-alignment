\section {Results}
\label{results}

\subsection {Analysis} 
%Since $H_{1}$ concerns the mean count of xyz for each word, a one-tailed Student's Independent \textit{t}-test will be used here to determine whether the mean count of xyz for nouns are statistically significantly greater than those for adjectivs.  The threshold for significance adopted here is $0.01$.  

\subsection{Total MAE (Error Over All Imitation Types)}
Figure \ref{fig:overall} shows the overall error for each variation of the genetic algorithm. Overall, the best algorithm was algorithm 1 with an MAE of $184.89$ while the worst, algorithm 8, had an MAE of $188.82$. Since the genetic alignment algorithms are all deterministic in nature, these errors are always the same. Subsequently, their standard deviation is 0 and their average is what they are. This makes them statistically significantly different. Thus, with $p < 0.00...01$, algorithm 1 is better than all other algorithms thus far demonstrated.

\begin{figure}[center]
	\centering
	\includegraphics[width=16cm]{images/error_type_all_imitations.png}
	\caption{Note that genetic alignment outperformed baseline in all cases.}
	\label{fig:overall}
\end{figure}

\subsection{Error By Imitation Class}
Figures \ref{fig:c1}-\ref{fig:6} demonstrate that the various versions of genetic alignment behave differently. This is expected behavior: Their preferences cause them to be more adept for certain imitation classes. The best genetic algorithm for each class is given in table \ref{tab:best-for-each}.

\begin{table}[center]
	\centering
	\begin{center}
		\begin{tabular}{|l|c|c|} \hline
			\textbf{Imitation Type}	& \textbf{Best Algorithm}	&	\textbf{Error (MAE)}	\\ \hline \hline
			1			& 1				&	54.15			\\ \hline
			2			& 1				&	82.81			\\ \hline
			3			& 1				&	87.59			\\ \hline
			4			& 1				&	92.42			\\ \hline
			5			& 1				&	93.38			\\ \hline
			6			& 1				&	101.43			\\ \hline
		\end{tabular}
	\end{center}
	\caption{Algorithm 1 has the best MAE for all the imitation types.}
	\label{tab:best-for-each}
\end{table}

Interestingly, algorithm 1 ends up being the best algorithm regardless of type. Algorithm 1 combined wih MLP ends up being the best high-order combinational model. 

\begin{figure}[center]
	\centering
	\includegraphics[width=16cm]{images/error_type_1_imitations.png}
	\caption{}
	\label{fig:c1}
\end{figure}
\begin{figure}[center]
	\centering
	\includegraphics[width=16cm]{images/error_type_2_imitations.png}
	\caption{}
	\label{fig:c2}
\end{figure}
\begin{figure}[center]
	\centering
	\includegraphics[width=16cm]{images/error_type_3_imitations.png}
	\caption{}
	\label{fig:c3}
\end{figure}
\begin{figure}[center]
	\centering
	\includegraphics[width=16cm]{images/error_type_4_imitations.png}
	\caption{}
	\label{fig:c4}
\end{figure}
\begin{figure}[center]
	\centering
	\includegraphics[width=16cm]{images/error_type_5_imitations.png}
	\caption{}
	\label{fig:c5}
\end{figure}
\begin{figure}[center]
	\centering
	\includegraphics[width=16cm]{images/error_type_6_imitations.png}
	\caption{}
	\label{fig:c6}
\end{figure}

%\subsection{Best in Each Category}
%Figures xyz %~\ref{theoreticalCombinedError} 
%shows the lowest error achieved for each imitation type.

\clearpage

\subsection{BP-trained MLP Performance}
(xyz fill this in)

\begin{figure}[center]
	\centering
	\includegraphics[width=16cm]{images/total_error_all_approaches.png}
	\caption{Regression provided by machine learning trumps the errors for genetic alignment. Furthermore, higher-ordered MLP models provide the lowest errors.}
	\label{fig:overall_ml}
\end{figure}

It is 
\begin{figure}[center]
	\centering
	\includegraphics[width=12cm]{images/Perceptron_vs_ML.png}
	\caption{An interesting correlation that lows in perceptron are highs in MLP.}
	\label{fig:perceptron_vs_bp}
\end{figure}
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%sample helps from previous research
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\input{results-all-responses}


%The Welch's \textit{t}-test agrees that there is significance (equal variance not assumed):%
%	\begin{quote}
%		$t(5)=4.1642, p < 0.00439413$
%	\end{quote}

%\subsection{}
%Since there were few responses from men (only 9), it seems that running the same \textit{t}-test on the responses without the male responses could be of interest as well.  Tables~\ref{tab:female_adjective}, \ref{tab:female_noun} show the normalized responses and total counts for each set of xyz while Table~\ref{tab:female_group_stats} shows the group statistics for the two groups.


%The calculated statistic is as follows (equal variance not assumed):
%$t(7.881)=3.55902, p < 0.00461577$ 
